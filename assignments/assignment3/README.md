# 3rd Assignment: Project Proposal

## 과제 개요

이번 과제부터 Assignment 6까지 진행될 **ML 기반 도구/서비스/어플리케이션 만들기 프로젝트**의 첫 단계입니다.
이 프로젝트를 통해 Machine Learning을 활용한 실용적인 도구를 직접 기획하고 구현하게 됩니다.

**이것은 개인 프로젝트입니다.** 각자 본인의 문제를 해결하는 도구를 만들어보세요.

### 전체 프로젝트 구성

| Assignment | 주제 | 설명 |
|-----------|------|------|
| **Assignment 3** | **Project Proposal** | 프로젝트 주제 설정 및 제안서 작성 |
| Assignment 4 | Data Collection and Analysis | 데이터 수집 및 분석 |
| Assignment 5 | Model Training and Evaluation | 모델 학습 및 평가 |
| Assignment 6 | Real Usage and Final Report | 실제 사용 및 최종 보고서 |

### Assignment 3의 목표

프로젝트 아이디어를 구체화하고 제안서를 작성합니다. **가장 중요한 것은 본인이 실제로 5번 이상 사용할 만한, 본인의 실제 문제를 해결하는 도구여야 한다는 것입니다.** 어떤 문제를 해결할 것인지, 어떤 데이터와 ML 기법을 활용할 것인지 명확히 정의하는 단계입니다.

### 중요한 요구사항

1. **실제 사용성**: 본인이 정말로 5번 이상 사용할 만한 도구여야 합니다
2. **문제 해결**: 본인이 겪고 있는 실제 문제를 해결해야 합니다
3. **ML 모델 학습**: Assignment 5에서 최소 한 번은 ML 모델을 직접 학습시켜봐야 합니다
   - 단, 최종 결과물에서 반드시 그 모델을 사용해야 하는 것은 아닙니다
   - 학습 및 평가 후, 공개 모델이나 LLM API가 더 적합하다면 그것을 사용해도 됩니다
   - 중요한 것은 모델 학습 및 평가 경험입니다

---

## 제출 방법

> 이 과제는 브라우저만으로 제출 가능합니다. CLI(터미널) 설정은 선택이며, 앞으로도 원하지 않으면 사용할 필요는 없습니다. 단, 향후 Git / GitHub 을 제대로 활용함에 있어 개인 환경에서 CLI 설정을 하시는 것을 **적극** 추천합니다.

- `projects/` 디렉토리에 프로젝트 제안서를 작성해서 PR로 제출하세요!
    - [https://github.com/HUFS-LAI-Seungtaek/HUFS-LAI-ML4E-2025-2](https://github.com/HUFS-LAI-Seungtaek/HUFS-LAI-ML4E-2025-2) 접속
    - `Fork` 버튼 클릭하여 `Create Fork` 진행
    - Fork한 repository(예: [https://github.com/hist0613/HUFS-LAI-ML4E-2025-2](https://github.com/hist0613/HUFS-LAI-ML4E-2025-2))로 이동 확인 후
    - `Add file` > `Create new file` 클릭
    - `projects/{학번}_{프로젝트명}/proposal.md` 파일에 프로젝트 제안서 작성
        - 예시: `projects/2025122_paper-translator-bot/proposal.md`
        - 프로젝트명은 영어로 작성하며, 단어 사이는 하이픈(`-`)으로 연결
    - 제안서 작성 후 `Commit changes...` 버튼 클릭
    - 본인 repository 메인 화면에서 `Contribute` > `Open pull request` 버튼 클릭
    - 아래와 같은 포맷으로 작성 후 `Create pull request` 버튼 클릭
        - Title: `3rd Assignment by {학번} ({영어 이름})`
            - 예시: `3rd Assignment by 2025122 (Seungtaek Choi)`
            - 학번/이름은 제출 식별·관리(제출 체크 및 채점 기록) 자동화에 사용됩니다
            - 해당 포맷을 지키지 않아 생기는 문제는 본인 책임입니다. 제출 전/후로 여러번 확인해주세요
            - `3rd assignment`, `third Assignment` 같은 포맷은 허용되지 않습니다
        - Description:
            ```markdown
            - `projects/{학번}_{프로젝트명}/proposal.md` 파일 제출합니다.
            - 프로젝트명: {한글 프로젝트명}
            ```

---

## 프로젝트 제안서 작성 가이드

`projects/{학번}_{프로젝트명}/proposal.md` 파일을 자유로운 형식으로 작성하세요.
**정해진 템플릿은 없습니다.** 본인이 생각하는 방식으로 프로젝트를 설명하면 됩니다.

### 반드시 포함되어야 할 내용

1. **해결하고자 하는 문제**
   - 본인이 겪고 있는 실제 문제가 무엇인가?
   - 왜 이 문제를 해결하고 싶은가?
   - 이 도구를 본인이 실제로 사용할 것인가?

2. **제안하는 솔루션**
   - 어떤 도구/서비스를 만들 것인가?
   - 주요 기능은 무엇인가?
   - 사용자(본인)가 어떻게 사용하게 될 것인가?

3. **ML 활용 계획**
   - 어떤 ML 기법/모델을 사용할 것인가?
   - 어떤 데이터를 수집하고 분석할 것인가?
   - Assignment 5에서 어떤 모델을 학습시켜볼 계획인가?

4. **기술적 접근**
   - 어떤 기술 스택을 사용할 것인가?
   - 전체 시스템 구조는 어떻게 될 것인가?
   - 최종 결과물의 형태는? (웹, 봇, CLI, 앱 등)

### 작성 팁

- **자유로운 형식**: Markdown으로 작성하되, 형식은 자유롭게
- **구체적으로**: 막연한 아이디어보다는 구체적인 계획을
- **현실적으로**: 한 학기 내에 완성 가능한 범위로
- **진솔하게**: 실제로 본인이 사용할 도구를 제안하세요
- **예시 참고**: 아래 예시들을 참고하여 작성해보세요 (그대로 따라하지 말 것)

---

## 프로젝트 예시

아이디어가 떠오르지 않는다면 아래 예시를 참고하세요. **단, 예시를 그대로 따라하지 말고 본인만의 문제와 아이디어를 추가하세요.**

---

### 예시 1: arXiv 논문 자동 추천 Slack 봇

#### 해결하고자 하는 문제

연구실이나 스터디 그룹에서 매일 쏟아지는 논문들을 일일이 확인하기 어렵습니다. arXiv에는 매일 수백 편의 논문이 올라오지만, 내 연구 분야에 관련된 논문만 골라서 보기가 힘듭니다. 또한 Abstract만 봐서는 논문의 핵심을 빠르게 파악하기 어렵습니다.

**실제 사용 시나리오**:
- 매일 아침 9시, 전날 올라온 NLP 관련 논문들이 자동으로 Slack에 요약과 함께 전달됨
- 연구실 팀원들과 함께 흥미로운 논문을 공유하고 토론
- 한 달에 최소 20일 이상 사용 예상

#### 제안하는 솔루션

arXiv API를 활용하여 특정 분야(예: cs.CL, cs.LG)의 최신 논문을 자동으로 수집하고, LLM을 활용해 3줄 요약과 함께 Slack 채널에 전송하는 봇입니다.

**주요 기능**:
1. **자동 논문 수집**: 매일 정해진 시간에 arXiv에서 새 논문 크롤링
2. **AI 기반 요약**: LLM을 활용해 Abstract를 3줄로 요약
3. **분야별 필터링**: 사용자가 관심있는 카테고리만 선택적으로 구독
4. **Slack 통합**: 지정된 채널에 자동으로 메시지 전송
5. **상호작용**: 멘션으로 특정 논문 상세 정보 요청 가능

**사용 흐름**:
```
1. 사용자: settings.py에서 관심 분야 설정 (예: ["cs.CL", "cs.IR"])
2. 봇: 매일 자정 arXiv API로 해당 분야 최신 논문 조회
3. 봇: 각 논문의 Abstract를 LLM으로 3줄 요약 생성
4. 봇: 오전 9시에 Slack 채널에 논문 목록 + 요약 전송
5. 사용자: 관심있는 논문의 PDF 링크 클릭하여 다운로드
```

#### ML 활용 계획

**1단계 (Assignment 4): 데이터 수집 및 분석**
- arXiv API를 통해 최근 3개월간 cs.CL 분야 논문 500편 수집
- 논문 메타데이터 분석 (제목, Abstract, 저자, 카테고리 등)
- Abstract 길이 분포, 주요 키워드 분석

**2단계 (Assignment 5): 모델 학습 및 평가**
- **학습 모델**: 논문 Abstract 분류 모델
  - 데이터: arXiv 논문 Abstract + 카테고리 라벨
  - 모델: BERT 기반 텍스트 분류 모델 (Hugging Face Transformers)
  - 목표: 논문이 어떤 세부 주제인지 자동 분류 (예: Machine Translation, Question Answering, Summarization 등)
  - 평가: Accuracy, F1-score 측정
- **대안 고려**: 직접 학습한 모델 vs. GPT-4 API
  - 학습 모델의 성능이 충분하면 사용
  - 그렇지 않으면 LLM API 사용 (더 유연한 요약 가능)

**3단계 (Assignment 6): 최종 구현**
- Assignment 5 평가 결과에 따라 최종 요약 모델 결정
- 실제로 매일 사용하면서 유용성 검증
- 사용 로그 분석 (어떤 논문을 많이 클릭했는지 등)

#### 기술적 접근

**시스템 구조**:
```
┌─────────────┐
│ arXiv API   │  ← 매일 최신 논문 조회
└──────┬──────┘
       │
       ▼
┌─────────────────────────┐
│ main.py (스케줄러)       │  ← Cron/APScheduler로 매일 실행
└──────┬──────────────────┘
       │
       ▼
┌─────────────────────────┐
│ api/arxiv.py            │  ← 논문 메타데이터 파싱
└──────┬──────────────────┘
       │
       ▼
┌─────────────────────────┐
│ summarizer.py           │  ← LLM으로 요약 생성
│ (OpenAI API or 학습모델) │
└──────┬──────────────────┘
       │
       ▼
┌─────────────────────────┐
│ api/slack.py            │  ← Slack에 메시지 전송
└─────────────────────────┘
```

**주요 컴포넌트**:
1. **settings.py**: 설정 관리
   - Slack token, OpenAI API key
   - 구독할 arXiv 카테고리 목록
   - 메시지 전송 시간 설정

2. **api/arxiv.py**: arXiv API 연동
   - 특정 카테고리의 최신 논문 조회
   - 논문 메타데이터 파싱 (제목, 저자, Abstract, PDF URL)

3. **api/slack.py**: Slack API 연동
   - 메시지 포맷팅 (Rich text blocks)
   - 채널에 메시지 전송
   - 멘션 이벤트 처리

4. **summarizer.py**: 요약 생성
   - LLM API 호출 (또는 학습된 모델 사용)
   - Prompt engineering (3줄 요약 생성)

5. **main.py**: 메인 실행 로직
   - 스케줄링 (매일 실행)
   - 전체 파이프라인 조율

**기술 스택**:
- **언어**: Python 3.10+
- **API**: arXiv API, Slack API, OpenAI API (또는 Anthropic Claude API)
- **라이브러리**:
  - `requests`: API 호출
  - `slack-sdk`: Slack 연동
  - `openai` 또는 `anthropic`: LLM API
  - `transformers`, `torch`: 모델 학습 (Assignment 5)
  - `APScheduler`: 스케줄링
- **배포**: 로컬 서버 또는 클라우드 (AWS EC2, Google Cloud Run 등)

**참고 레포지토리**: [arxivbot](https://github.com/hist0613/arxivbot)

#### 예상되는 어려움과 해결 방안

1. **LLM API 비용**
   - 해결: 무료 티어 활용 (Claude Haiku, GPT-3.5-turbo)
   - 또는 논문 수 제한 (하루 10편까지만)

2. **요약 품질**
   - 해결: Prompt engineering으로 개선
   - Few-shot learning 예시 추가

3. **Slack 봇 호스팅**
   - 해결: 개인 서버에서 24시간 실행
   - 또는 GitHub Actions로 스케줄링

---

### 예시 2: 학과 공지 자동 분류 및 알람 디스코드 봇

#### 해결하고자 하는 문제

학과 홈페이지 공지사항을 매일 확인하는 것이 번거롭고, 중요한 공지(장학금, 수강신청 등)를 놓치는 경우가 많습니다. 모든 공지를 다 읽기에는 시간이 부족하고, 본인에게 관련 없는 공지도 많습니다.

**실제 사용 시나리오**:
- 매일 오후 6시, 새로운 공지가 있으면 자동으로 디스코드 DM 수신
- 장학금 관련 공지는 즉시 알림
- 학기 중 매일 사용 예상

#### 제안하는 솔루션

학과 홈페이지를 자동으로 크롤링하여 공지사항을 수집하고, ML 모델로 카테고리와 중요도를 분류한 뒤, 사용자가 설정한 관심사에 맞춰 디스코드로 알림을 보내는 봇입니다.

**주요 기능**:
1. **자동 크롤링**: 매시간 학과 홈페이지 공지사항 체크
2. **자동 분류**: 공지를 카테고리별로 분류 (학사, 장학금, 행사, 취업 등)
3. **중요도 판단**: 긴급/일반/참고로 우선순위 설정
4. **개인화 알림**: 사용자가 관심있는 카테고리만 알림
5. **요약**: 긴 공지의 핵심 내용 요약

#### ML 활용 계획

**Assignment 4**:
- 과거 공지사항 500개 크롤링
- 수동으로 카테고리 라벨링 (학사, 장학금, 행사, 취업, 기타)
- 텍스트 전처리 및 키워드 분석

**Assignment 5**:
- **학습 모델**: 텍스트 분류 모델
  - 데이터: 공지사항 제목+본문 + 카테고리 라벨
  - 모델: Logistic Regression, Random Forest, KoBERT
  - 목표: 새 공지의 카테고리 자동 예측
  - 평가: 5-fold cross-validation으로 정확도 측정
- **중요도 판단 모델**: 키워드 기반 규칙 + 분류 모델

**Assignment 6**:
- 실제 사용하며 잘못 분류된 공지 수집
- 모델 재학습으로 성능 개선

#### 기술 스택

- **언어**: Python
- **크롤링**: BeautifulSoup, Selenium (JavaScript 렌더링 필요 시)
- **ML**: scikit-learn, Transformers (KoBERT)
- **봇**: Discord.py
- **스케줄링**: Cron 또는 APScheduler
- **DB**: SQLite (중복 체크용)

---

### 예시 3: 개인화된 영한 번역 도구

#### 해결하고자 하는 문제

기존 번역기(Google, DeepL)는 좋지만, 본인이 선호하는 표현이나 문체를 반영하지 못합니다. 특히 기술 문서나 논문 번역 시, 전문 용어의 일관성이 부족하고, 본인의 번역 스타일과 맞지 않는 경우가 많습니다.

**실제 사용 시나리오**:
- 논문 읽으면서 영어 문장을 즉시 번역
- 본인이 선호하는 용어로 자동 변환
- 주 5회 이상 사용 예상

#### 제안하는 솔루션

기본 번역 엔진(DeepL API)에 개인화 레이어를 추가하여, 사용자의 피드백을 학습해 개인 맞춤형 번역을 제공하는 CLI/웹 도구입니다.

**주요 기능**:
1. **기본 번역**: DeepL API로 초벌 번역
2. **피드백 수집**: 번역 결과를 수정하면 학습 데이터로 저장
3. **개인화 모델**: 사용자의 선호 표현을 학습
4. **용어집 관리**: 전문 용어 매핑 테이블 자동 생성
5. **번역 히스토리**: 과거 번역 검색 가능

#### ML 활용 계획

**Assignment 4**:
- 본인의 과거 번역 데이터 100쌍 수집
- 기존 번역기 결과 vs. 본인이 수정한 결과 비교 분석

**Assignment 5**:
- **학습 모델**: Post-editing 모델
  - 데이터: (원문, 기계번역, 본인의 수정본) 삼중쌍
  - 모델: Sequence-to-sequence 모델 (mBART 또는 T5)
  - 목표: 기계번역 결과를 본인 스타일로 교정
  - 평가: BLEU score, 수동 평가
- **대안**: 데이터가 부족하면 용어집 기반 규칙 + LLM API 사용

**Assignment 6**:
- 실제 사용하며 피드백 계속 수집
- 100회 사용 후 성능 변화 측정

#### 기술 스택

- **언어**: Python
- **번역 API**: DeepL API
- **ML**: Transformers (mBART, T5), PyTorch
- **인터페이스**: Streamlit (웹) 또는 Typer (CLI)
- **DB**: SQLite (번역 히스토리 저장)

---

## 추가 리소스

### Markdown 가이드
Markdown 문법이 익숙하지 않다면 아래 가이드를 참고하세요:
- [Markdown 사용법 가이드](./guides/markdown.md)

### GitHub 가이드
GitHub 사용이 처음이거나 복습이 필요하다면:
- [GitHub 기본 사용법 가이드](./guides/github.md)

---

## Assignment 3 평가 기준

이 과제는 **Pass / Non-Pass**로만 평가됩니다.

### Pass 기준

1. **제출 완료**: PR이 정상적으로 생성되고 merge 가능한 상태
2. **내용 적절성**: 아래 항목들이 포함되어 있음
   - 해결하고자 하는 실제 문제
   - 제안하는 솔루션
   - ML 활용 계획
   - 기술적 접근 방법

### Non-Pass 사유

- PR 형식이 맞지 않아 merge 불가능
- 제안서가 너무 간략하여 프로젝트 내용 파악 불가
- ML과 무관한 프로젝트
- 명백히 실현 불가능한 프로젝트

**중요**: Assignment 3 자체는 Pass/Non-Pass 평가이지만, **최종 프로젝트(Assignment 6)는 아래 기준으로 평가**됩니다.

---

## 최종 프로젝트 평가 기준 (Assignment 6)

최종 프로젝트는 **최종 보고서(Final Report)와 발표(Presentation)**를 기준으로 평가됩니다.

| 항목 | 배점 | 설명 |
|-----|------|------|
| **문제 정의 및 실용성** | 25% | 실제 본인의 문제를 해결하는가? 5번 이상 사용했는가? |
| **ML 모델 학습 및 평가** | 25% | Assignment 5에서 모델을 직접 학습하고 평가했는가? |
| **구현 완성도** | 20% | 제안한 기능이 실제로 동작하는가? |
| **데이터 수집 및 분석** | 15% | 적절한 데이터를 수집하고 분석했는가? |
| **최종 보고서 및 발표** | 15% | 프로젝트 과정과 결과를 명확히 설명했는가? |

### 세부 평가 항목

#### 1. 문제 정의 및 실용성 (25%)
- 본인이 겪는 실제 문제를 명확히 정의했는가?
- 실제로 도구를 5번 이상 사용했다는 증거가 있는가?
- 사용 로그, 스크린샷 등으로 실사용 증명

#### 2. ML 모델 학습 및 평가 (25%)
- Assignment 5에서 ML 모델을 직접 학습시켰는가?
- 학습 데이터 구성이 적절한가?
- 모델 평가 방법이 타당한가?
- 학습한 모델을 최종 결과물에 사용하지 않아도 됨
  - 단, 왜 사용하지 않았는지 합리적 설명 필요
  - 예: "BERT 분류 모델을 학습했으나 GPT-4 API가 더 정확해서 최종적으로는 API 사용"

#### 3. 구현 완성도 (20%)
- 제안서의 핵심 기능이 구현되었는가?
- 코드 품질 (가독성, 구조화)
- 버그 없이 정상 동작하는가?
- GitHub 레포지토리에 코드 및 README 작성

#### 4. 데이터 수집 및 분석 (15%)
- Assignment 4에서 적절한 데이터를 수집했는가?
- 데이터 탐색 및 분석이 충분한가?
- 데이터 품질 관리를 했는가?

#### 5. 최종 보고서 및 발표 (15%)
- 프로젝트 전체 과정을 명확히 문서화했는가?
- 발표에서 핵심 내용을 효과적으로 전달했는가?
- 어려움과 해결 방안을 솔직하게 공유했는가?

---

## FAQ

**Q: ML 모델을 반드시 학습시켜야 하나요?**
A: 네, Assignment 5에서 최소 한 번은 ML 모델을 직접 학습시켜봐야 합니다. 단, 최종 결과물에서 그 모델을 사용해야 하는 것은 아닙니다. 학습 및 평가 후, 공개 모델이나 API가 더 적합하다고 판단되면 그것을 사용해도 됩니다.

**Q: 프로젝트 주제를 바꿀 수 있나요?**
A: Assignment 3 제출 마감 전까지는 자유롭게 수정 가능합니다. 이후에는 담당 교수/조교와 상의 후 변경 가능합니다.

**Q: 팀 프로젝트인가요?**
A: 아닙니다. 개인 프로젝트입니다.

**Q: 프로젝트 예시를 그대로 사용해도 되나요?**
A: 예시는 참고용입니다. 예시와 동일한 프로젝트는 권장하지 않습니다. 본인만의 문제와 아이디어를 추가하세요.

**Q: 정말로 5번 이상 사용해야 하나요?**
A: 네, 이것이 가장 중요한 기준입니다. 본인이 실제로 사용하지 않는 도구는 의미가 없습니다. 최종 보고서에서 사용 증거(로그, 스크린샷 등)를 제출해야 합니다.

**Q: 데이터를 직접 수집해야 하나요?**
A: 공개 데이터셋을 사용해도 되지만, 본인의 문제에 맞게 가공하거나 추가 수집이 필요할 수 있습니다. Assignment 4에서 데이터 수집 및 분석 과정을 거칩니다.

**Q: LLM API 사용만으로도 괜찮나요?**
A: 최종 결과물에서는 괜찮습니다. 하지만 Assignment 5에서는 최소 한 번 모델을 직접 학습시켜봐야 합니다. 예를 들어, 번역 봇을 만든다면:
- Assignment 5: 번역 품질 평가를 위해 간단한 분류 모델 학습
- Assignment 6: 최종적으로는 GPT-4 API 사용 (학습한 모델보다 성능이 좋다고 판단)

---

## 제출 마감

- **마감일**: {마감일 추가 필요}
- **제출 방법**: GitHub Pull Request
- **지각 제출**: 마감일 이후 제출 시 Non-Pass 처리될 수 있음

---

## 마무리

이 프로젝트의 핵심은 **"본인이 실제로 사용할 도구를 만드는 것"**입니다.

**좋은 프로젝트의 조건**:
- ✅ 본인이 겪고 있는 실제 문제를 해결
- ✅ 완성 후 5번 이상 사용할 것
- ✅ ML 모델을 학습하고 평가해볼 수 있는 구조
- ✅ 한 학기 내에 완성 가능한 범위

**피해야 할 프로젝트**:
- ❌ 이미 좋은 솔루션이 있는데 굳이 만드는 것
- ❌ 본인이 사용하지 않을 것
- ❌ ML과 무관하거나, ML이 불필요한 것
- ❌ 너무 단순하거나 너무 복잡한 것

본인의 문제를 해결하면서 ML을 배우는 값진 경험이 되길 바랍니다.

**Good luck with your project! 🚀**
