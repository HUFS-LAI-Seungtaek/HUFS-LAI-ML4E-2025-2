{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284ce7be",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size=784, hidden_size=589, num_classes=10): #hidden_size 100 -> 589\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        순전파 함수 // forward propagation\n",
    "        x: 입력 텐서 (batch_size, 784)\n",
    "        return: 출력 텐서 (batch_size, 10)\n",
    "        \"\"\"\n",
    "        return self.layers(x)\n",
    "\n",
    "# 모델 생성 및 구조 확인\n",
    "model = MLP()\n",
    "print(\"모델 구조:\")\n",
    "print(model)\n",
    "\n",
    "# 파라미터 개수 계산\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\n총 파라미터 수: {total_params:,}\")\n",
    "print(f\"학습 가능한 파라미터 수: {trainable_params:,}\")\n",
    "\n",
    "# 각 레이어별 파라미터 수 확인\n",
    "print(\"\\n레이어별 파라미터:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.shape} ({param.numel():,} 개)\")\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 138        # 배치 크기 128 -> 138\n",
    "test_batch_size = 1000  # 테스트 배치 크기 (메모리 효율을 위해 크게 설정)\n",
    "learning_rate = 1e-3    # 학습률 (0.001)\n",
    "nb_epochs = 4           # 에포크 수 3 -> 4\n",
    "\n",
    "print(\"=== 하이퍼파라미터 ===\")\n",
    "print(f\"배치 크기: {batch_size}\")\n",
    "print(f\"테스트 배치 크기: {test_batch_size}\")\n",
    "print(f\"학습률: {learning_rate}\")\n",
    "print(f\"에포크 수: {nb_epochs}\")\n",
    "\n",
    "# 디바이스 설정 (GPU가 있으면 GPU 사용)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\n사용 디바이스: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"GPU 이름: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU 메모리: {torch.cuda.get_device_properties(0).total_memory // 1024**3} GB\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
