# MNIST 분류 실험 결과
---
## 기본 모델 성능
- 최종 테스트 정확도: 96.96%
- 훈련 시간: 57초
---
## 실험 결과

### 실험 1: 하이퍼파라미터 그리드 탐색
- 변경사항: 학습률 [0.01, 0.001, 0.0001], 은닉층 크기 [50, 100, 200], 에포크 수 [5, 10]의 모든 조합, 즉 총 18가지의 방안 중 최적의 조합을 탐색함.
- **결과**: 학습률 0.001, 은닉층 크기 200, 에포크 10 조합에서 테스트 정확도 97.87%로 최고 성능을 기록함.
- 분석: 학습률은 0.001이 가장 이상적인 값이었다. 너무 높으면 학습이 불안정했고, 너무 낮으면 학습이 더디게 나타났다. 은닉층 크기 및 에포크는 적절한 학습률 하에서, 모델의 용량과 훈련량이 클수록 좋은 성능을 내는 경향을 보였다.

### 실험 2: 모델 구조 변경에 따른 성능 비교
- **변경사항**: 실험 1의 우수 하이퍼파라미터(lr=0.001, epochs=10)를 고정한 채, 기본 모델, 3층/4층의 깊은 모델, 그리고 각각에 드롭아웃을 적용한 모델 등 총 6가지 구조를 테스트하였다.
- 결과: 가장 단순한 구조인 Baseline 모델이 97.99%로 가장 높은 정확도를 기록했다. 층을 더 깊게 쌓거나 드롭아웃을 추가했을 때는 모든 경우에서 성능이 하락했다.
- 분석: 모델 깊이: MNIST는 비교적 간단한 문제라, 이미 기본 모델이 충분한 표현력을 가지고 있어 층을 추가하는 것이 오히려 미세한 성능 저하를 유발한 것으로 보인다. Dropout은 모델이 과적합이 약한 상태였으므로 불필요한 방해 요소로 작용하여 전반적인 성능을 하락시켰다.
---
## 결론 및 인사이트
- **가장 효과적인 개선 방법**: 실험 1에서 찾은 최적의 하이퍼파라미터(lr=0.001, epochs=10)를 Baseline에 적용했을 때 97.99%라는 최고 정확도를 달성했다.

- **관찰된 패턴**:
  - 가장 단순한 모델이 가장 좋은 성능을 보였다. 이는 문제의 복잡도에 비해 모델이 과도하게 복잡할 필요가 없다는 것을 보여준다.
  - 학습률이 모델 성능에 가장 결정적인 영향을 미쳤다.
  - Dropout은 항상 성능을 향상시키는 것이 아니며, 모델의 상태를 분석하고 필요할 때 적용해야 효과적이다.

- **추가 개선 아이디어**:
  - 이미지 처리에 더 특화된 CNN(Convolution Neural Network) 모델을 도입하여 MLP의 구조적 한계를 넘어설 수 있는지 확인해볼 수 있을 것이다. 또한 SGD와 같은 다른 옵티마이저를 적용할 경우 최적 학습률이 달라질 수 있으므로, 이에 대한 추가 탐색이 유의미할 것이다.