# -*- coding: utf-8 -*-

"""
[Assignment 5] Evaluation Notebook
- ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ
- Test Dataset ë¡œë“œ
- ROUGE Score ì¸¡ì • ë° ê²°ê³¼ ë¶„ì„
"""

# ==========================================
# 0. Notebook widget metadata ê¹¨ì§ ë°©ì§€ ì½”ë“œ
# ==========================================
# tqdm, datasets, evaluate ë‚´ë¶€ì—ì„œ ë°œìƒí•˜ëŠ” HTML widgetì„ ëª¨ë‘ ë¹„í™œì„±í™”
import os
os.environ["DISABLE_COLAB_WIDGETS"] = "1"

# tqdmì„ í…ìŠ¤íŠ¸ ëª¨ë“œë¡œ ê°•ì œ (HTML widget ìƒì„± ë°©ì§€)
from tqdm import tqdm as _tqdm
def tqdm(*args, **kwargs):
    kwargs["disable"] = False      # ì¶œë ¥ì€ ìœ ì§€
    kwargs["ascii"] = True         # widget ì•„ë‹Œ ASCII progress bar
    return _tqdm(*args, **kwargs)


# ==========================================
# 1. í™˜ê²½ ì„¤ì • ë° ë°ì´í„° ë¡œë“œ
# ==========================================
import sys
import subprocess

try:
    import evaluate
except ImportError:
    subprocess.check_call([sys.executable, "-m", "pip", "install",
                           "evaluate", "rouge_score", "transformers",
                           "datasets", "accelerate"])

from google.colab import drive
import os
import pandas as pd
import torch
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
from datasets import Dataset
import evaluate

# Google Drive ë§ˆìš´íŠ¸
drive.mount('/content/drive')

# ê²½ë¡œ ì„¤ì • (Trainingì—ì„œ ì €ì¥í•œ ê²½ë¡œì™€ ë™ì¼í•´ì•¼ í•¨)
PROJECT_DIR = "/content/drive/MyDrive/NLP_Assignment5"
MODEL_SAVE_DIR = os.path.join(PROJECT_DIR, "final_model")
DATA_SAVE_DIR = os.path.join(PROJECT_DIR, "data")

# Test ë°ì´í„° ë¡œë“œ
test_csv_path = os.path.join(DATA_SAVE_DIR, "test_dataset.csv")
if not os.path.exists(test_csv_path):
    raise FileNotFoundError("Test Datasetì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Trainingì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")

test_df = pd.read_csv(test_csv_path)
print(f"ğŸ“‚ Test Data ë¡œë“œ ì™„ë£Œ: {len(test_df)}ê±´")


# ==========================================
# 2. ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
# ==========================================
print(f"ğŸ¤– ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ ì¤‘... ({MODEL_SAVE_DIR})")
device = "cuda" if torch.cuda.is_available() else "cpu"

tokenizer = AutoTokenizer.from_pretrained(MODEL_SAVE_DIR)
model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_SAVE_DIR).to(device)


# ==========================================
# 3. í‰ê°€ ì§€í‘œ ì„¤ì • (ROUGE)
# ==========================================
# datasets/evaluateì˜ widget ê¸°ë°˜ progress bar ë¹„í™œì„±í™”
os.environ["TOKENIZERS_PARALLELISM"] = "false"

rouge = evaluate.load("rouge")

def generate_summary(text):
    inputs = tokenizer(text, return_tensors="pt", max_length=512, truncation=True).to(device)
    with torch.no_grad():
        summary_ids = model.generate(
            inputs["input_ids"],
            max_length=128,
            min_length=30,
            length_penalty=2.0,
            num_beams=4,
            early_stopping=True
        )
    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)


# ==========================================
# 4. ì„±ëŠ¥ í‰ê°€ (Inference Loop)
# ==========================================
print("\nğŸ§ª í‰ê°€ ì§„í–‰ ì¤‘ (ROUGE Score ê³„ì‚°)...")

predictions = []
references = []

for idx, row in tqdm(test_df.iterrows(), total=len(test_df)):
    doc = row["document"]
    ref = row["summary"]

    pred = generate_summary(doc)

    predictions.append(pred)
    references.append(ref)

# ROUGE ì ìˆ˜ ê³„ì‚°
results = rouge.compute(predictions=predictions, references=references)


# ==========================================
# 5. ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥
# ==========================================
print("\nğŸ“Š [Final Evaluation Results]")
print("-" * 30)
print(f"ROUGE-1: {results['rouge1']:.4f}")
print(f"ROUGE-2: {results['rouge2']:.4f}")
print(f"ROUGE-L: {results['rougeL']:.4f}")
print("-" * 30)

# ê²°ê³¼ DataFrame ì €ì¥
eval_result_df = pd.DataFrame({
    "document": test_df["document"],
    "reference": references,
    "prediction": predictions
})
eval_result_df.to_csv("evaluation_results.csv", index=False, encoding="utf-8-sig")
print("âœ… ìƒì„¸ ê²°ê³¼ê°€ 'evaluation_results.csv'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ìƒ˜í”Œ ì¶œë ¥
print("\nğŸ‘€ [ìƒ˜í”Œ ê²°ê³¼ í™•ì¸]")
for i in range(3):
    print(f"\nExample {i+1}:")
    print(f"Original : {test_df.iloc[i]['document'][:100]}...")
    print(f"Reference: {references[i]}")
    print(f"Generated: {predictions[i]}")
