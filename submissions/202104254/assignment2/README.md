# MNIST 분류 실험 결과

## 기본 모델 성능
- 최종 테스트 정확도: 96.67%
- 훈련 시간: 60.59초

## 실험 결과
- 10개의 케이스를 분류하여 테스트를 실시하였고 각각의 상세한 내용은 assignment2 폴더 내의 엑셀 파일에 정리함

## 결론 및 인사이트
- 전체적인 경향성
- 정확도 측면: nb_epochs를 늘릴수록 (예: 실험 1,3,8,10) 정확도가 향상되는 경향이 강함. 그러나 learning_rate가 너무 작으면 (실험 2,7,9) underfitting으로 정확도가 하락. hidden_size 증가 (200)는 잠재적 향상을 가져오지만, 학습률과 에포크가 적절히 맞춰지지 않으면 효과가 반감됨. Dropout 추가는 일반화에 도움을 주어 정확도를 안정화시킴 (실험 9,10).
- 훈련 시간 측면: nb_epochs 증가가 시간 증가의 주요 원인 (실험 1,3,8,9,10에서 150~190초). batch_size 감소 (64)는 한 에포크당 연산 횟수가 많아져 시간 증가 (실험 1,2,3). hidden_size 증가 (200)는 연산량 증가로 약간의 시간 상승 (실험 5,7,8,9). 전체적으로 에포크와 배치 크기가 시간에 가장 큰 영향을 줌.
- 과적합 정도 측면: 대부분 실험에서 과적합이 기본(0.21%)보다 줄었음. nb_epochs 증가와 Dropout 추가가 과적합을 줄이는 데 효과적 (음수 값 다수). learning_rate 감소는 underfitting을 유발해 과적합을 음수로 만듦 (실험 2,3,7,9). 큰 learning_rate (0.005)는 과적합 위험 증가 (실험 5,8). 경향: 긴 학습과 regularization(Dropout)이 과적합을 효과적으로 제어함.

- 전체적으로, MNIST처럼 간단한 데이터셋에서는 에포크 증가와 적절한 regularization이 성능 향상에 핵심적이며, 학습률은 0.001 정도가 균형 잡힌 선택으로 보임. 더 복잡한 모델(큰 hidden_size)에서는 하이퍼파라미터 최적화가 필수적일 것으로 보임.
