## MNIST 분류 실험 결과
## 기본 모델 성능
최종 테스트 정확도: 97.84%
훈련 시간: 1분 3초
## 실험 결과
1. 은닉층 증가, 에포크 수 증가
오버피팅만 계속해서 일어날 뿐, 실행 횟수 증가하는 동안 97%에서 98% 부근 이후로는 유의미한 정확도 향상이 나타나지 않음. 또한 에포크 수 증가의 경우 실행 시간이 과도하게 늘어난다는 단점을 확인할 수 있었음.
2. hidden size 100->200으로 증가, 배치 크기 256, 에포크 수 5로 설정.
훈련 정확도와 테스트 정확도를 모두 97% 후반에서 98% 초반대로 안정적으로 향상시킬 수 있는 안정적인 결과 도출. 이 설정에서 추가로 학습률을 조정하거나 에포크 수를 여기서 더 많이 늘리더라도 훈련 시간의 증가와 함께 과적합만 계속해서 악화시키는 결과가 나오는 것으로 보아 과도하게 늘리는 것 또한 도움이 되지 않음. 이 값 설정이 여러 요소를 동시에 고려할 때 가장 적합한 결과를 도출할 수 있는 이상적인 모델로 판단.
## 결론 및 인사이트
무조건적으로 학습을 많이 시킨다고 해서 모델의 성능이 좋아지지만은 않는다는 점을 확인할 수 있음. 또한 값을 변경할 때 한 가지만 변경하는 것이 아니라 다른 값들과 균형을 생각하며 조절해야 이상적인 결과가 도출된다는 점을 미루어 보았을 때, ai 모델은 여러 설정값이 복합적으로 영향을 주고받아 그 성능을 결정함을 짐작할 수 있었음.
